# Cell 1: Setup and Imports
"""
Causal Time Series Analysis for Supply Chain Optimization
Interactive Analysis Notebook
"""

import sys
import os

sys.path.append("..")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings("ignore")

from config import Config
from src.data_preprocessing import DataPreprocessor
from src.causal_analysis import CausalAnalyzer
from src.time_series_models import TimeSeriesModels
from src.optimization import SupplyChainOptimizer
from src.visualization import SupplyChainVisualizer

# Set plotting style
plt.style.use("seaborn-v0_8")
sns.set_palette("husl")

print("All modules imported successfully!")

# Cell 2: Initialize Components
config = Config()
preprocessor = DataPreprocessor(config)
causal_analyzer = CausalAnalyzer(config)
ts_models = TimeSeriesModels(config)
optimizer = SupplyChainOptimizer(config)
visualizer = SupplyChainVisualizer(config)

print("Components initialized!")

# Cell 3: Data Generation and Preprocessing
# Generate synthetic supply chain data
print("Generating synthetic supply chain data...")
raw_data = preprocessor.generate_synthetic_data(
    start_date="2020-01-01", end_date="2024-12-31"
)

print(f"Generated {len(raw_data)} data points")
print(f"Date range: {raw_data['date'].min()} to {raw_data['date'].max()}")
print(f"Columns: {list(raw_data.columns)}")

# Display basic statistics
raw_data.describe()

# Cell 4: Data Cleaning and Feature Engineering
# Clean the data
cleaned_data = preprocessor.clean_data(raw_data)

# Create additional features
feature_data = preprocessor.create_features(cleaned_data)

# Prepare for modeling
modeling_data = preprocessor.prepare_for_modeling(
    feature_data, target_variable="demand"
)

print(f"Final dataset shape: {modeling_data['data'].shape}")
print(f"Causal features: {modeling_data['causal_features']}")
print(f"Time features: {len(modeling_data['time_features'])} features")
print(f"Outcome features: {modeling_data['outcome_features']}")

# Cell 5: Exploratory Data Analysis
# Plot key time series
fig, axes = plt.subplots(2, 2, figsize=(16, 10))

# Demand over time
axes[0, 0].plot(modeling_data["data"]["date"], modeling_data["data"]["demand"])
axes[0, 0].set_title("Demand Over Time")
axes[0, 0].set_ylabel("Demand")

# Inventory levels
axes[0, 1].plot(modeling_data["data"]["date"], modeling_data["data"]["inventory_level"])
axes[0, 1].set_title("Inventory Levels")
axes[0, 1].set_ylabel("Inventory")

# Price trends
axes[1, 0].plot(modeling_data["data"]["date"], modeling_data["data"]["price"])
axes[1, 0].set_title("Price Trends")
axes[1, 0].set_ylabel("Price")

# Service level
axes[1, 1].plot(modeling_data["data"]["date"], modeling_data["data"]["service_level"])
axes[1, 1].set_title("Service Level")
axes[1, 1].set_ylabel("Service Level")

plt.tight_layout()
plt.show()

# Cell 6: Correlation Analysis
# Calculate correlation matrix
corr_data = modeling_data["data"][
    [
        "demand",
        "price",
        "promotional_activity",
        "weather_score",
        "inventory_level",
        "service_level",
        "total_cost",
    ]
].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_data, annot=True, cmap="coolwarm", center=0)
plt.title("Correlation Matrix of Key Variables")
plt.show()

# Cell 7: Causal Analysis
print("Running causal analysis...")

# Define treatment-outcome pairs
treatment_outcome_pairs = [
    ("price", "demand"),
    ("promotional_activity", "demand"),
    ("weather_score", "demand"),
    ("supplier_reliability", "inventory_level"),
]

# Run causal analysis
causal_results = causal_analyzer.comprehensive_causal_analysis(
    modeling_data["data"], treatment_outcome_pairs
)

# Display results
for pair, results in causal_results.items():
    print(f"\n{pair}:")
    if "error" in results:
        print(f"  Error: {results['error']}")
    else:
        if "treatment_effects" in results:
            for method, effect in results["treatment_effects"].items():
                print(f"  {method}: {effect:.4f}")

# Cell 8: Visualize Causal Effects
if causal_results:
    causal_plot = visualizer.plot_causal_effects(causal_results)
    plt.show()

# Cell 9: Time Series Modeling
print("Training time series models...")

# Train all models
model_performance = ts_models.train_all_models(
    modeling_data["data"], target_col="demand", test_size=0.2
)

# Display model performance
performance_df = pd.DataFrame(model_performance).T
print("Model Performance:")
print(performance_df)

# Cell 10: Visualize Model Performance
if model_performance:
    perf_plot = visualizer.plot_model_performance(model_performance)
    plt.show()

# Cell 11: Generate Forecasts
print("Generating forecasts...")

# Get forecasts from all models
forecast_periods = 30
forecasts = {}

for model_name in ts_models.models.keys():
    try:
        forecast = ts_models.forecast_future(
            modeling_data["data"], periods=forecast_periods, model_name=model_name
        )
        forecasts[model_name] = forecast
        print(f"Generated forecast for {model_name}")
    except Exception as e:
        print(f"Forecast failed for {model_name}: {str(e)}")

# Visualize forecasts
if forecasts and ts_models.predictions:
    # Get test data for comparison
    test_size = 0.2
    split_idx = int(len(modeling_data["data"]) * (1 - test_size))
    test_data = modeling_data["data"][split_idx:]

    forecast_plot = visualizer.plot_forecasts(
        test_data["demand"].values,
        list(ts_models.predictions.values()),
        list(ts_models.predictions.keys()),
    )
    plt.show()

# Cell 12: Supply Chain Optimization
print("Running supply chain optimization...")

# Get best model for optimization
if model_performance:
    best_model = min(model_performance.items(), key=lambda x: x[1]["RMSE"])[0]
    print(f"Using {best_model} for optimization")

    # Generate demand forecast
    demand_forecast = ts_models.forecast_future(
        modeling_data["data"], periods=30, model_name=best_model
    )

    # Run optimization
    optimization_results = optimizer.comprehensive_optimization(
        modeling_data["data"], demand_forecast
    )

    print("Optimization completed!")

    # Display results
    for method, results in optimization_results.items():
        print(f"\n{method.upper()} OPTIMIZATION:")
        if "optimal_params" in results:
            print(f"  Optimal Parameters: {results['optimal_params']}")
        if "optimal_cost" in results:
            print(f"  Optimal Cost: {results['optimal_cost']:.2f}")
        if "performance_metrics" in results:
            print(f"  Performance Metrics: {results['performance_metrics']}")

# Cell 13: Visualize Optimization Results
if "optimization_results" in locals():
    opt_plot = visualizer.plot_optimization_results(optimization_results)
    plt.show()

# Cell 14: Interactive Dashboard
print("Creating interactive dashboard...")

# Create interactive dashboard
interactive_fig = visualizer.plot_interactive_dashboard(
    modeling_data["data"], ts_models.predictions, causal_results
)

# Display dashboard
interactive_fig.show()

# Cell 15: Sensitivity Analysis
print("Running sensitivity analysis...")


# Example sensitivity analysis for reorder point
def sensitivity_analysis(base_params, param_name, param_range, demand_forecast):
    results = []

    for param_value in param_range:
        test_params = base_params.copy()
        test_params[param_name] = param_value

        # Convert dict to list for optimization function
        param_list = [
            test_params["reorder_point"],
            test_params["order_quantity"],
            test_params["safety_stock"],
        ]

        cost = optimizer.inventory_cost_function(
            param_list, demand_forecast, config.CONSTRAINTS
        )

        results.append({"param_value": param_value, "cost": cost})

    return pd.DataFrame(results)


# Run sensitivity analysis if optimization was successful
if "optimization_results" in locals() and "single_objective" in optimization_results:
    base_params = optimization_results["single_objective"]["optimal_params"]

    # Sensitivity for reorder point
    reorder_sensitivity = sensitivity_analysis(
        base_params, "reorder_point", np.linspace(10, 200, 20), demand_forecast
    )
    # Cell 15: Sensitivity Analysis (continued)
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(reorder_sensitivity["param_value"], reorder_sensitivity["cost"], "b-o")
    plt.title("Sensitivity: Reorder Point vs Cost")
    plt.xlabel("Reorder Point")
    plt.ylabel("Total Cost")
    plt.grid(True, alpha=0.3)

    # Sensitivity for order quantity
    order_sensitivity = sensitivity_analysis(
        base_params, "order_quantity", np.linspace(50, 500, 20), demand_forecast
    )

    plt.subplot(1, 2, 2)
    plt.plot(order_sensitivity["param_value"], order_sensitivity["cost"], "r-o")
    plt.title("Sensitivity: Order Quantity vs Cost")
    plt.xlabel("Order Quantity")
    plt.ylabel("Total Cost")
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# Cell 16: Scenario Analysis
print("Running scenario analysis...")

# Create different demand scenarios
scenarios = {
    "optimistic": demand_forecast * 1.2,
    "pessimistic": demand_forecast * 0.8,
    "volatile": demand_forecast * (1 + 0.3 * np.random.randn(len(demand_forecast))),
    "seasonal_peak": demand_forecast
    * (1 + 0.4 * np.sin(np.linspace(0, 4 * np.pi, len(demand_forecast)))),
}

scenario_results = {}
for scenario_name, scenario_demand in scenarios.items():
    scenario_demand = np.maximum(scenario_demand, 0)  # Ensure non-negative demand

    result = optimizer.optimize_inventory_policy(scenario_demand, method="scipy")
    scenario_results[scenario_name] = result

# Visualize scenario results
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Optimal costs by scenario
costs = [result["optimal_cost"] for result in scenario_results.values()]
scenarios_names = list(scenario_results.keys())

ax1.bar(scenarios_names, costs, color=["green", "red", "orange", "purple"])
ax1.set_title("Optimal Costs by Scenario")
ax1.set_ylabel("Total Cost")
ax1.tick_params(axis="x", rotation=45)

# Parameters comparison
params_df = pd.DataFrame(
    {name: result["optimal_params"] for name, result in scenario_results.items()}
).T

params_df.plot(kind="bar", ax=ax2)
ax2.set_title("Optimal Parameters by Scenario")
ax2.set_ylabel("Parameter Value")
ax2.tick_params(axis="x", rotation=45)
ax2.legend()

plt.tight_layout()
plt.show()

# Cell 17: Risk Analysis
print("Conducting risk analysis...")

# Monte Carlo simulation for demand uncertainty
n_simulations = 1000
np.random.seed(42)

# Generate random demand scenarios
base_demand = demand_forecast
demand_std = np.std(modeling_data["data"]["demand"])

simulation_results = []
for i in range(n_simulations):
    # Add random noise to base demand
    random_demand = base_demand + np.random.normal(
        0, demand_std * 0.3, len(base_demand)
    )
    random_demand = np.maximum(random_demand, 0)

    # Optimize for this demand scenario
    try:
        result = optimizer.optimize_inventory_policy(random_demand, method="scipy")
        simulation_results.append(
            {
                "cost": result["optimal_cost"],
                "service_level": result["performance_metrics"]["service_level"],
                "reorder_point": result["optimal_params"]["reorder_point"],
                "order_quantity": result["optimal_params"]["order_quantity"],
            }
        )
    except:
        continue

if simulation_results:
    sim_df = pd.DataFrame(simulation_results)

    # Plot risk analysis results
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Cost distribution
    axes[0, 0].hist(sim_df["cost"], bins=30, alpha=0.7, edgecolor="black")
    axes[0, 0].axvline(
        sim_df["cost"].mean(),
        color="red",
        linestyle="--",
        label=f"Mean: {sim_df['cost'].mean():.2f}",
    )
    axes[0, 0].set_title("Cost Distribution")
    axes[0, 0].set_xlabel("Total Cost")
    axes[0, 0].legend()

    # Service level distribution
    axes[0, 1].hist(sim_df["service_level"], bins=30, alpha=0.7, edgecolor="black")
    axes[0, 1].axvline(
        sim_df["service_level"].mean(),
        color="red",
        linestyle="--",
        label=f"Mean: {sim_df['service_level'].mean():.3f}",
    )
    axes[0, 1].set_title("Service Level Distribution")
    axes[0, 1].set_xlabel("Service Level")
    axes[0, 1].legend()

    # Cost vs Service Level trade-off
    axes[1, 0].scatter(sim_df["service_level"], sim_df["cost"], alpha=0.6)
    axes[1, 0].set_title("Cost vs Service Level Trade-off")
    axes[1, 0].set_xlabel("Service Level")
    axes[1, 0].set_ylabel("Total Cost")

    # Parameter stability
    axes[1, 1].scatter(
        sim_df["reorder_point"],
        sim_df["order_quantity"],
        c=sim_df["cost"],
        cmap="viridis",
        alpha=0.6,
    )
    axes[1, 1].set_title("Parameter Stability (colored by cost)")
    axes[1, 1].set_xlabel("Reorder Point")
    axes[1, 1].set_ylabel("Order Quantity")

    plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1], label="Total Cost")
    plt.tight_layout()
    plt.show()

    # Risk metrics
    cost_var = np.var(sim_df["cost"])
    cost_95_percentile = np.percentile(sim_df["cost"], 95)
    service_level_5_percentile = np.percentile(sim_df["service_level"], 5)

    print(f"Risk Metrics:")
    print(f"  Cost Variance: {cost_var:.2f}")
    print(f"  95th Percentile Cost: {cost_95_percentile:.2f}")
    print(f"  5th Percentile Service Level: {service_level_5_percentile:.3f}")

# Cell 18: What-If Analysis
print("Conducting what-if analysis...")


# What if lead times increase?
def what_if_lead_time_increase(data, increase_factor=1.5):
    """Analyze impact of increased lead times"""
    modified_data = data.copy()
    modified_data["lead_time"] = modified_data["lead_time"] * increase_factor

    # Recalculate inventory dynamics
    new_inventory = preprocessor._simulate_inventory(
        modified_data["demand"], modified_data["lead_time"]
    )
    modified_data["inventory_level"] = new_inventory
    modified_data["stockout_rate"] = (modified_data["inventory_level"] <= 0).astype(int)
    modified_data["service_level"] = 1 - modified_data["stockout_rate"]

    return modified_data


# What if demand volatility increases?
def what_if_demand_volatility(data, volatility_factor=2.0):
    """Analyze impact of increased demand volatility"""
    modified_data = data.copy()
    demand_mean = modified_data["demand"].mean()
    demand_noise = (modified_data["demand"] - demand_mean) * volatility_factor
    modified_data["demand"] = demand_mean + demand_noise
    modified_data["demand"] = np.maximum(modified_data["demand"], 0)

    return modified_data


# Run what-if scenarios
base_data = modeling_data["data"]

# Scenario 1: Increased lead times
scenario_1 = what_if_lead_time_increase(base_data, 1.5)

# Scenario 2: Increased demand volatility
scenario_2 = what_if_demand_volatility(base_data, 2.0)

# Compare scenarios
fig, axes = plt.subplots(2, 2, figsize=(16, 10))

# Service level comparison
scenarios_data = {
    "Base": base_data["service_level"].mean(),
    "Increased Lead Time": scenario_1["service_level"].mean(),
    "Higher Volatility": scenario_2["service_level"].mean(),
}

axes[0, 0].bar(
    scenarios_data.keys(), scenarios_data.values(), color=["blue", "orange", "red"]
)
axes[0, 0].set_title("Average Service Level by Scenario")
axes[0, 0].set_ylabel("Service Level")
axes[0, 0].tick_params(axis="x", rotation=45)

# Inventory level comparison
inv_data = {
    "Base": base_data["inventory_level"].mean(),
    "Increased Lead Time": scenario_1["inventory_level"].mean(),
    "Higher Volatility": base_data[
        "inventory_level"
    ].mean(),  # Demand volatility doesn't directly change inventory
}

axes[0, 1].bar(inv_data.keys(), inv_data.values(), color=["blue", "orange", "red"])
axes[0, 1].set_title("Average Inventory Level by Scenario")
axes[0, 1].set_ylabel("Inventory Level")
axes[0, 1].tick_params(axis="x", rotation=45)

# Time series comparison - Service Level
axes[1, 0].plot(base_data["date"], base_data["service_level"], label="Base", alpha=0.7)
axes[1, 0].plot(
    scenario_1["date"],
    scenario_1["service_level"],
    label="Increased Lead Time",
    alpha=0.7,
)
axes[1, 0].plot(
    scenario_2["date"],
    scenario_2["service_level"],
    label="Higher Volatility",
    alpha=0.7,
)
axes[1, 0].set_title("Service Level Over Time")
axes[1, 0].set_ylabel("Service Level")
axes[1, 0].legend()

# Demand comparison
axes[1, 1].plot(base_data["date"], base_data["demand"], label="Base", alpha=0.7)
axes[1, 1].plot(
    scenario_2["date"], scenario_2["demand"], label="Higher Volatility", alpha=0.7
)
axes[1, 1].set_title("Demand Patterns")
axes[1, 1].set_ylabel("Demand")
axes[1, 1].legend()

plt.tight_layout()
plt.show()

# Cell 19: Summary and Insights
print("=" * 80)
print("ANALYSIS SUMMARY AND KEY INSIGHTS")
print("=" * 80)

# Model Performance Summary
print("\n1. MODEL PERFORMANCE:")
if model_performance:
    best_model = min(model_performance.items(), key=lambda x: x[1]["RMSE"])
    print(f"   Best Model: {best_model[0]} (RMSE: {best_model[1]['RMSE']:.2f})")

    for model, metrics in model_performance.items():
        print(f"   {model}: RMSE={metrics['RMSE']:.2f}, R²={metrics['R2']:.3f}")

# Causal Effects Summary
print("\n2. KEY CAUSAL EFFECTS:")
if causal_results:
    for pair, results in causal_results.items():
        if "error" not in results and "treatment_effects" in results:
            if "linear_regression" in results["treatment_effects"]:
                effect = results["treatment_effects"]["linear_regression"]
                print(f"   {pair}: {effect:.4f}")

# Optimization Summary
print("\n3. OPTIMIZATION RESULTS:")
if "optimization_results" in locals():
    for method, results in optimization_results.items():
        if "optimal_cost" in results:
            print(f"   {method}: Cost = {results['optimal_cost']:.2f}")

# Risk Analysis Summary
print("\n4. RISK ANALYSIS:")
if "sim_df" in locals():
    print(f"   Average Cost: {sim_df['cost'].mean():.2f} ± {sim_df['cost'].std():.2f}")
    print(f"   Average Service Level: {sim_df['service_level'].mean():.3f}")
    print(f"   Cost at Risk (95th percentile): {cost_95_percentile:.2f}")

# Business Recommendations
print("\n5. BUSINESS RECOMMENDATIONS:")
print("   • Implement dynamic reordering based on demand forecasts")
print("   • Monitor causal factors that significantly impact demand")
print("   • Establish safety stock policies considering demand uncertainty")
print("   • Regular model retraining to maintain forecast accuracy")
print("   • Consider multi-objective optimization for balanced performance")

print("\n" + "=" * 80)

# Cell 20: Export Results
print("Exporting results...")

# Create results directory
import os

results_dir = "../results"
os.makedirs(results_dir, exist_ok=True)

# Export data
modeling_data["data"].to_csv(f"{results_dir}/processed_data.csv", index=False)

# Export model performance
if model_performance:
    pd.DataFrame(model_performance).T.to_csv(f"{results_dir}/model_performance.csv")

# Export optimization results
if "optimization_results" in locals():
    import json

    with open(f"{results_dir}/optimization_results.json", "w") as f:
        json.dump(optimization_results, f, indent=2, default=str)

# Export forecasts
if forecasts:
    forecast_df = pd.DataFrame(forecasts)
    forecast_df.to_csv(f"{results_dir}/forecasts.csv", index=False)

# Export risk analysis
if "sim_df" in locals():
    sim_df.to_csv(f"{results_dir}/risk_analysis.csv", index=False)

print(f"Results exported to {results_dir}/")
print("Analysis completed successfully!")
